{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = 'sandwiches'\n",
    "\n",
    "def pruning_function(business):\n",
    "    for category in business['categories']:\n",
    "        if category.lower() == cuisine:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "mexican_restaurants = []\n",
    "restaurant_ids = set()\n",
    "\n",
    "with open('../data/business.json') as data_file:    \n",
    "    all_businesses = [json.loads(line) for line in list(data_file)]\n",
    "    restaurants_list = list(filter(pruning_function, all_businesses))\n",
    "    for line in restaurants_list:\n",
    "        mexican_restaurants.append({'business_id': line['business_id'], 'name': line['name']})\n",
    "        restaurant_ids.add(line['business_id'])\n",
    "mexican_restaurants = pd.DataFrame(mexican_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reviews = []\n",
    "with open('../data/review.json', encoding=\"utf8\") as data_file:\n",
    "    count = 0\n",
    "    for line in (data_file):\n",
    "        row = json.loads(line)\n",
    "        if row['business_id'] in restaurant_ids:\n",
    "            reviews.append({'business_id':row['business_id'],'text':row['text']})\n",
    "reviews = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(topic, review, n=4):\n",
    "    phrases_list = []\n",
    "    size = len(review)\n",
    "    for index, word in enumerate(review):\n",
    "        if word == topic:        \n",
    "            if index - n >= 0:\n",
    "                before_portion = review[index-n:index]\n",
    "            else:\n",
    "                before_portion = review[0:index]\n",
    "            if index + n + 1 < size:\n",
    "                after_portion = review[index:index + n +1]\n",
    "            else:\n",
    "                after_portion = review[index:size]\n",
    "            phrases_list.append(\" \".join(before_portion + after_portion).lower())\n",
    "    return(phrases_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stop_words(review, stop_words = stops):\n",
    "    return [word for word in review if word not in stops]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "import string\n",
    "translator =  str.maketrans('', '', string.punctuation)\n",
    "\n",
    "temp = pd.merge(reviews, mexican_restaurants)\n",
    "# for review in reviews:\n",
    "count = 0\n",
    "\n",
    "# print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "stops.add('br')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "import string\n",
    "translator =  str.maketrans('', '', string.punctuation)\n",
    "\n",
    "\n",
    "def remove_stop_words(review):\n",
    "    middle = [stemmer.stem(word) for word in review.translate(translator).lower().split()]\n",
    "    return ' '.join([word for word in middle if word not in stops])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reviews = []\n",
    "with open('../data/review.json', encoding=\"utf8\") as data_file:\n",
    "    count = 0\n",
    "    for line in (data_file):\n",
    "        row = json.loads(line)\n",
    "        if row['business_id'] in restaurant_ids:\n",
    "            reviews.append({'business_id':row['business_id'],'text':row['text']})\n",
    "reviews = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# sns.set(color_codes=True)\n",
    "# %matplotlib qt \n",
    "\n",
    "# # print(positive_scores)\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# xs = np.arange(len(bar.index.tolist()))\n",
    "# width = 0.5\n",
    "# plt.bar(xs, bar, width, align='center')\n",
    "\n",
    "# _ = plt.xticks(xs, bar.index.tolist(), rotation='vertical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['text'] = reviews['text'].apply(remove_stop_words)\n",
    "bar = pd.Series(' '.join(reviews['text']).split()).value_counts()[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['place', 'food', 'good', 'order', 'sandwich', 'great', 'like', 'time', 'get', 'go', 'servic', 'one', 'tri', 'back', 'pizza', 'realli', 'friend', 'love', 'would', 'come', 'also', 'wait', 'got', 'salad', 'chees', 'delici', 'make', 'eat', 'best', 'dont', 'nice', 'chicken', 'im', 'even', 'well', 'fri', 'want', 'alway', 'ive', 'fresh', 'littl', 'look', 'tast', 'price', 'restaur', 'menu', 'us', 'lunch', 'staff', 'bread', 'definit', 'came', 'first', 'locat', 'didnt', 'amaz', 'breakfast', 'ask', 'much', 'tabl', 'pretti', 'drink', 'sauc', 'burger', 'made', 'thing', 'say', 'meat', 'went', 'better', 'peopl', 'never', 'take', 'could', 'coffe', 'know', 'day', 'think', 'side', 'way', 'flavor', 'give', 'minut', 'recommend', 'meal', 'work', 'two', 'right', 'perfect', 'star', 'lot', 'custom', 'everyth', 'ever', 'enjoy', 'top', 'visit', 'busi', 'sure', 'serv']\n"
     ]
    }
   ],
   "source": [
    "print(bar.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = set(['food', 'order', 'place', 'sandwich', 'pizza', 'salad', 'chees', 'chicken', 'fri', 'restaur',\n",
    "              'lunch', 'staff', 'bread', 'breakfast', 'drink', 'sauc', 'burger', 'meat', 'coffee', 'side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "mexican_dict = {row[1]: topics for row in mexican_restaurants.itertuples()}\n",
    "with open('./restaurant_topics/sandwiches.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in mexican_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "# import string\n",
    "# translator =  str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# temp = pd.merge(reviews, mexican_restaurants)\n",
    "# # for review in reviews:\n",
    "# count = 0\n",
    "\n",
    "# for row in temp.groupby('business_id'):\n",
    "#     for review in row[1]['text']:\n",
    "#         for topic in topics:\n",
    "#             if topic in review:\n",
    "#                 cleaned_review = clean_review(topic, remove_stop_words(review.translate(translator).split()), 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
