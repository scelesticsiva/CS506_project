{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = 'fast food'\n",
    "\n",
    "def pruning_function(business):\n",
    "    for category in business['categories']:\n",
    "        if category.lower() == cuisine:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "mexican_restaurants = []\n",
    "restaurant_ids = set()\n",
    "\n",
    "with open('../data/business.json') as data_file:    \n",
    "    all_businesses = [json.loads(line) for line in list(data_file)]\n",
    "    restaurants_list = list(filter(pruning_function, all_businesses))\n",
    "    for line in restaurants_list:\n",
    "        mexican_restaurants.append({'business_id': line['business_id'], 'name': line['name']})\n",
    "        restaurant_ids.add(line['business_id'])\n",
    "mexican_restaurants = pd.DataFrame(mexican_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reviews = []\n",
    "with open('../data/review.json', encoding=\"utf8\") as data_file:\n",
    "    count = 0\n",
    "    for line in (data_file):\n",
    "        row = json.loads(line)\n",
    "        if row['business_id'] in restaurant_ids:\n",
    "            reviews.append({'business_id':row['business_id'],'text':row['text']})\n",
    "reviews = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(topic, review, n=4):\n",
    "    phrases_list = []\n",
    "    size = len(review)\n",
    "    for index, word in enumerate(review):\n",
    "        if word == topic:        \n",
    "            if index - n >= 0:\n",
    "                before_portion = review[index-n:index]\n",
    "            else:\n",
    "                before_portion = review[0:index]\n",
    "            if index + n + 1 < size:\n",
    "                after_portion = review[index:index + n +1]\n",
    "            else:\n",
    "                after_portion = review[index:size]\n",
    "            phrases_list.append(\" \".join(before_portion + after_portion).lower())\n",
    "    return(phrases_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stop_words(review, stop_words = stops):\n",
    "    return [word for word in review if word not in stops]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "import string\n",
    "translator =  str.maketrans('', '', string.punctuation)\n",
    "\n",
    "temp = pd.merge(reviews, mexican_restaurants)\n",
    "# for review in reviews:\n",
    "count = 0\n",
    "\n",
    "# print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "stops.add('br')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "import string\n",
    "translator =  str.maketrans('', '', string.punctuation)\n",
    "\n",
    "\n",
    "def remove_stop_words(review):\n",
    "    middle = [stemmer.stem(word) for word in review.translate(translator).lower().split()]\n",
    "    return ' '.join([word for word in middle if word not in stops])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reviews = []\n",
    "with open('../data/review.json', encoding=\"utf8\") as data_file:\n",
    "    count = 0\n",
    "    for line in (data_file):\n",
    "        row = json.loads(line)\n",
    "        if row['business_id'] in restaurant_ids:\n",
    "            reviews.append({'business_id':row['business_id'],'text':row['text']})\n",
    "reviews = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# sns.set(color_codes=True)\n",
    "# %matplotlib qt \n",
    "\n",
    "# # print(positive_scores)\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# xs = np.arange(len(bar.index.tolist()))\n",
    "# width = 0.5\n",
    "# plt.bar(xs, bar, width, align='center')\n",
    "\n",
    "# _ = plt.xticks(xs, bar.index.tolist(), rotation='vertical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food',\n",
       " 'order',\n",
       " 'place',\n",
       " 'good',\n",
       " 'get',\n",
       " 'time',\n",
       " 'like',\n",
       " 'go',\n",
       " 'one',\n",
       " 'burger',\n",
       " 'fri',\n",
       " 'chicken',\n",
       " 'servic',\n",
       " 'great',\n",
       " 'locat',\n",
       " 'back',\n",
       " 'tri',\n",
       " 'alway',\n",
       " 'would',\n",
       " 'dont',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'got',\n",
       " 'love',\n",
       " 'friend',\n",
       " 'eat',\n",
       " 'wait',\n",
       " 'im',\n",
       " 'even',\n",
       " 'make',\n",
       " 'want',\n",
       " 'fast',\n",
       " 'also',\n",
       " 'ask',\n",
       " 'ive',\n",
       " 'sandwich',\n",
       " 'custom',\n",
       " 'sauc',\n",
       " 'tast',\n",
       " 'staff',\n",
       " 'fresh',\n",
       " 'never',\n",
       " 'well',\n",
       " 'chee',\n",
       " 'didnt',\n",
       " 'look',\n",
       " 'restaur',\n",
       " 'drive',\n",
       " 'give',\n",
       " 'nice',\n",
       " 'say',\n",
       " 'first',\n",
       " 'know',\n",
       " 'peopl',\n",
       " 'price',\n",
       " 'minut',\n",
       " 'take',\n",
       " 'best',\n",
       " 'went',\n",
       " 'work',\n",
       " 'better',\n",
       " 'littl',\n",
       " 'much',\n",
       " 'hot',\n",
       " 'way',\n",
       " 'meal',\n",
       " 'pretti',\n",
       " 'thing',\n",
       " 'clean',\n",
       " 'pizza',\n",
       " 'us',\n",
       " 'manag',\n",
       " 'delici',\n",
       " 'could',\n",
       " 'line',\n",
       " 'came',\n",
       " 'ever',\n",
       " 'taco',\n",
       " 'right',\n",
       " 'think',\n",
       " 'said',\n",
       " 'made',\n",
       " 'employ',\n",
       " 'star',\n",
       " 'menu',\n",
       " 'two',\n",
       " 'drink',\n",
       " 'top',\n",
       " 'day',\n",
       " 'quick',\n",
       " '2',\n",
       " 'definit',\n",
       " 'bad',\n",
       " 'need',\n",
       " 'lunch',\n",
       " 'still',\n",
       " 'busi',\n",
       " 'burrito',\n",
       " 'seem',\n",
       " 'experi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews['text'] = reviews['text'].apply(remove_stop_words)\n",
    "bar = pd.Series(' '.join(reviews['text']).split()).value_counts()[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food', 'order', 'place', 'good', 'get', 'time', 'like', 'go', 'one', 'burger', 'fri', 'chicken', 'servic', 'great', 'locat', 'back', 'tri', 'alway', 'would', 'dont', 'realli', 'come', 'got', 'love', 'friend', 'eat', 'wait', 'im', 'even', 'make', 'want', 'fast', 'also', 'ask', 'ive', 'sandwich', 'custom', 'sauc', 'tast', 'staff', 'fresh', 'never', 'well', 'chee', 'didnt', 'look', 'restaur', 'drive', 'give', 'nice', 'say', 'first', 'know', 'peopl', 'price', 'minut', 'take', 'best', 'went', 'work', 'better', 'littl', 'much', 'hot', 'way', 'meal', 'pretti', 'thing', 'clean', 'pizza', 'us', 'manag', 'delici', 'could', 'line', 'came', 'ever', 'taco', 'right', 'think', 'said', 'made', 'employ', 'star', 'menu', 'two', 'drink', 'top', 'day', 'quick', '2', 'definit', 'bad', 'need', 'lunch', 'still', 'busi', 'burrito', 'seem', 'experi']\n"
     ]
    }
   ],
   "source": [
    "print(bar.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = set(['food', 'order', 'place', 'time', 'burger', 'fri', 'chicken', 'servic', 'sandwich', 'sauc',\n",
    "              'staff', 'chee', 'restaur', 'meal', 'pizza', 'taco', 'drink', 'lunch', 'burrito', 'drive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "mexican_dict = {row[1]: topics for row in mexican_restaurants.itertuples()}\n",
    "with open('./restaurant_topics/fast_food.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in mexican_dict.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "# import string\n",
    "# translator =  str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# temp = pd.merge(reviews, mexican_restaurants)\n",
    "# # for review in reviews:\n",
    "# count = 0\n",
    "\n",
    "# for row in temp.groupby('business_id'):\n",
    "#     for review in row[1]['text']:\n",
    "#         for topic in topics:\n",
    "#             if topic in review:\n",
    "#                 cleaned_review = clean_review(topic, remove_stop_words(review.translate(translator).split()), 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
